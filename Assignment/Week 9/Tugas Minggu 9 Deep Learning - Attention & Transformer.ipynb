{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tugas Minggu 9 Deep Learning - Attention & Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h2 align='center'> Tugas Minggu 9 Deep Learning </h2>\n",
        "<br>\n",
        "<hr>\n",
        "<br>\n",
        "Nama: Muh. Yusuf Syam\n",
        "<br>\n",
        "NIM: H071191044\n",
        "<br>\n",
        "Soal: Modern RNN <a href='https://d2l.ai/chapter_attention-mechanisms/index.html'> D2L.AI Chapter 10. Attention Mechanism - Dive into Deep Learning<a/>"
      ],
      "metadata": {
        "id": "pncdcFwSKlaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention adalah mekanisme deep learning yang memutuskan bagian mana yang perlu difokuskan dan bagian mana yang harus diabaikan. Seperti neural network, attention juga meniru cara kerja otak manusia yang mengabaikan sebagian besar informasi yang diterima, dan hanya memperhatikan proporsi kecil dari informasi yang dianggap penting, misalnya saat seseorang membaca buku, ia hanya fokus pada kata atau kalimat yang sedang ia baca, bukan pada keseluruhan buku. \n",
        "\n",
        "Salah satu keuntungan dari menggunakan mekanisme attention yaitu proses komputasi jauh lebih murah."
      ],
      "metadata": {
        "id": "fYtcosreVaB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Syarat Attention"
      ],
      "metadata": {
        "id": "ONdXI_WmWVJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention Poooling"
      ],
      "metadata": {
        "id": "ud-E7UA7Xt86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fungsi Attention Scoring"
      ],
      "metadata": {
        "id": "3Dx-pXqzXuCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bahdanau Attention"
      ],
      "metadata": {
        "id": "7pO1cDtCWgcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Head Attention"
      ],
      "metadata": {
        "id": "eNwKCv65X6wJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self-Attention dan Positional Encoding"
      ],
      "metadata": {
        "id": "cHTEtKn0X8ox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer"
      ],
      "metadata": {
        "id": "95LidcrQYAhZ"
      }
    }
  ]
}